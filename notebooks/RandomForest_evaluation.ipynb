{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we will be training a Random Forest to predict the scorline of EPL games using the existing pipeline pipeline_ex_RandomForest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Import and Data Prep\n",
    "\n",
    "We import the necessary libraries and get the training, validation and testing datasets. These sets have undergone cleaning, preparation and feature engeneering in the original pipeline file, so they are ready to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_RandomForest.py:190: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  db['odds_hw'] = db[home_win_cols].mean(axis=1)\n",
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_RandomForest.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  db['odds_d']  = db[draw_cols].mean(axis=1)\n",
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_RandomForest.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  db['odds_aw'] = db[away_win_cols].mean(axis=1)\n",
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_RandomForest.py:159: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  db[\"h2h_avg_home_goals_last_5\"].fillna(db[\"h2h_avg_home_goals_last_5\"].mean(), inplace=True)\n",
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_RandomForest.py:160: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  db[\"h2h_avg_away_goals_last_5\"].fillna(db[\"h2h_avg_away_goals_last_5\"].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- NaN Check before scaling ---\n",
      "NaNs in X_train: 0\n",
      "NaNs in X_val: 0\n",
      "NaNs in X_test: 0\n",
      "--- NaN Check after scaling ---\n",
      "NaNs in X_train_scaled: 0\n",
      "NaNs in X_val_scaled: 0\n",
      "NaNs in X_test_scaled: 0\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Evaluation Notebook\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "import sys, os\n",
    "\n",
    "# Import pipeline and load data\n",
    "sys.path.append(os.path.abspath('..'))  # Adjust if needed\n",
    "from pipeline_ex_RandomForest import get_train_val_test_data\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_train_val_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train type: <class 'pandas.core.frame.DataFrame'>\n",
      "X_train shape: (3233, 227)\n",
      "y_train type: <class 'pandas.core.frame.DataFrame'>\n",
      "y_train shape: (3233, 2)\n",
      "First 5 y_train columns: ['FTHG', 'FTAG']\n",
      "First 5 X_train columns: ['HTHG', 'HTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'Bb1X2', 'BbMxH', 'BbAvH', 'BbMxD', 'BbAvD', 'BbMxA', 'BbAvA', 'BbOU', 'BbMx_2.5', 'BbAv_2.5', 'BbMx_2.5', 'BbAv_2.5', 'BbAH', 'BbAHh', 'BbMxAHH', 'BbAvAHH', 'BbMxAHA', 'BbAvAHA', 'B365_2.5', 'B365_2.5', 'P_2.5', 'P_2.5', 'Max_2.5', 'Max_2.5', 'Avg_2.5', 'Avg_2.5', 'AHh', 'B365AHH', 'B365AHA', 'PAHH', 'PAHA', 'MaxAHH', 'MaxAHA', 'AvgAHH', 'AvgAHA', 'B365C_2.5', 'B365C_2.5', 'PC_2.5', 'PC_2.5', 'MaxC_2.5', 'MaxC_2.5', 'AvgC_2.5', 'AvgC_2.5', 'AHCh', 'B365CAHH', 'B365CAHA', 'PCAHH', 'PCAHA', 'MaxCAHH', 'MaxCAHA', 'AvgCAHH', 'AvgCAHA', 'BFEH', 'BFED', 'BFEA', 'BFE_2.5', 'BFE_2.5', 'BFEAHH', 'BFEAHA', 'BFECH', 'BFECD', 'BFECA', 'BFEC_2.5', 'BFEC_2.5', 'BFECAHH', 'BFECAHA', 'odds_hw', 'odds_d', 'odds_aw', 'HomeTeam_ID', 'AwayTeam_ID', 'avg_goals_L5_home', 'avg_goals_L5_away', 'avg_shots_home_L5', 'avg_shots_away_L5', 'avg_shots_ont_home_L5', 'avg_shots_ont_away_L5', 'avg_corners_home_L5', 'avg_corners_away_L5', 'avg_goals_conceded_home_L5', 'avg_goals_conceded_away_L5', 'avg_fouls_committed_home_L5', 'avg_fouls_committed_away_L5', 'win_rate_home_L5', 'win_rate_away_L5', 'draw_rate_home_L5', 'draw_rate_away_L5', 'loss_rate_home_L5', 'loss_rate_away_L5', 'home_strength_diff', 'offensive_index_home', 'offensive_index_away', 'defensive_solidity_home', 'defensive_solidity_away', 'h2h_avg_home_goals_last_5', 'h2h_avg_away_goals_last_5', 'HomeTeam_Arsenal', 'HomeTeam_Aston_Villa', 'HomeTeam_Bournemouth', 'HomeTeam_Brentford', 'HomeTeam_Brighton', 'HomeTeam_Burnley', 'HomeTeam_Cardiff', 'HomeTeam_Chelsea', 'HomeTeam_Crystal_Palace', 'HomeTeam_Everton', 'HomeTeam_Fulham', 'HomeTeam_Huddersfield', 'HomeTeam_Ipswich', 'HomeTeam_Leeds', 'HomeTeam_Leicester', 'HomeTeam_Liverpool', 'HomeTeam_Luton', 'HomeTeam_Man_City', 'HomeTeam_Man_United', 'HomeTeam_Manchester_City', 'HomeTeam_Manchester_United', 'HomeTeam_Newcastle', 'HomeTeam_Newcastle_United', 'HomeTeam_Norwich', \"HomeTeam_Nott'm_Forest\", 'HomeTeam_Nottingham_Forest', 'HomeTeam_Sheffield_United', 'HomeTeam_Southampton', 'HomeTeam_Stoke', 'HomeTeam_Swansea', 'HomeTeam_Tottenham', 'HomeTeam_Watford', 'HomeTeam_West_Bromwich_Albion', 'HomeTeam_West_Ham', 'HomeTeam_Wolverhampton_Wanderers', 'HomeTeam_Wolves', 'AwayTeam_Arsenal', 'AwayTeam_Aston_Villa', 'AwayTeam_Bournemouth', 'AwayTeam_Brentford', 'AwayTeam_Brighton', 'AwayTeam_Burnley', 'AwayTeam_Cardiff', 'AwayTeam_Chelsea', 'AwayTeam_Crystal_Palace', 'AwayTeam_Everton', 'AwayTeam_Fulham', 'AwayTeam_Huddersfield', 'AwayTeam_Ipswich', 'AwayTeam_Leeds', 'AwayTeam_Leicester', 'AwayTeam_Liverpool', 'AwayTeam_Luton', 'AwayTeam_Man_City', 'AwayTeam_Man_United', 'AwayTeam_Manchester_City', 'AwayTeam_Manchester_United', 'AwayTeam_Newcastle', 'AwayTeam_Newcastle_United', 'AwayTeam_Norwich', \"AwayTeam_Nott'm_Forest\", 'AwayTeam_Nottingham_Forest', 'AwayTeam_Sheffield_United', 'AwayTeam_Southampton', 'AwayTeam_Stoke', 'AwayTeam_Swansea', 'AwayTeam_Tottenham', 'AwayTeam_Watford', 'AwayTeam_West_Bromwich_Albion', 'AwayTeam_West_Ham', 'AwayTeam_Wolverhampton_Wanderers', 'AwayTeam_Wolves', 'Referee_A_Kitchen', 'Referee_A_Madley', 'Referee_A_Marriner', 'Referee_A_Moss', 'Referee_A_Taylor', 'Referee_C_Kavanagh', 'Referee_C_Pawson', 'Referee_D_Bond', 'Referee_D_Coote', 'Referee_D_England', 'Referee_D_Webb', 'Referee_G_Scott', 'Referee_J_Brooks', 'Referee_J_Gillett', 'Referee_J_Moss', 'Referee_J_Smith', 'Referee_K_Friend', 'Referee_K_Kavanagh', 'Referee_L_Mason', 'Referee_L_Probert', 'Referee_L_Smith', 'Referee_M_Atkinson', 'Referee_M_Dean', 'Referee_M_Donohue', 'Referee_M_Jones', 'Referee_M_Oliver', 'Referee_M_Salisbury', 'Referee_N_Swarbrick', 'Referee_O_Langford', 'Referee_O_Oliver', 'Referee_P_Bankes', 'Referee_P_Tierney', 'Referee_R_East', 'Referee_R_Jones', 'Referee_R_Madley', 'Referee_R_Welch', 'Referee_S_Allison', 'Referee_S_Attwell', 'Referee_S_Barrott', 'Referee_S_Hooper', 'Referee_S_Scott', 'Referee_S_Singh', 'Referee_T_Bramall', 'Referee_T_Harrington', 'Referee_T_Robinson']\n"
     ]
    }
   ],
   "source": [
    "# Check data types and shapes\n",
    "print(\"X_train type:\", type(X_train))\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train type:\", type(y_train))\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"First 5 y_train columns:\", y_train.columns.tolist())\n",
    "print(\"First 5 X_train columns:\", X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Hyperparameter Tuning\n",
    "\n",
    "We tune the hyperparemeters using GridSearchCV to get the optimal model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "Best parameters: {'estimator__max_depth': 5, 'estimator__max_features': None, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'estimator__n_estimators': 200}\n",
      "Best CV score (neg RMSE): -0.8333504182043974\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [3, 5, 7, None],\n",
    "    'estimator__min_samples_split': [2, 5, 10],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4],\n",
    "    'estimator__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Create time series cross-validation splits\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "base_model = MultiOutputRegressor(RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "grid = GridSearchCV(base_model, param_grid, cv=tscv, scoring='neg_root_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score (neg RMSE):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Validation Evaluation\n",
    "\n",
    "We validate the model and see how it performs on the validation set. This should give us an idea of how it performs and if the hyperparameter optimization was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE (raw): 0.48362443704865987\n",
      "Validation RMSE (rounded): 0.5705445544554455\n",
      "Validation MAE (raw): 0.5690365887115081\n",
      "Validation MAE (rounded): 0.5160891089108911\n",
      "Validation R2 (raw): 0.6799545925509689\n",
      "Validation R2 (rounded): 0.620746909881414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\jupyter_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\jupyter_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Validation set evaluation with rounded predictions\n",
    "y_val_pred = grid.predict(X_val.values)\n",
    "y_val_pred_rounded = np.round(y_val_pred)  # Round predictions to nearest integer\n",
    "\n",
    "print(\"Validation RMSE (raw):\", mean_squared_error(y_val, y_val_pred))\n",
    "print(\"Validation RMSE (rounded):\", mean_squared_error(y_val, y_val_pred_rounded))\n",
    "print(\"Validation MAE (raw):\", mean_absolute_error(y_val, y_val_pred))\n",
    "print(\"Validation MAE (rounded):\", mean_absolute_error(y_val, y_val_pred_rounded))\n",
    "print(\"Validation R2 (raw):\", r2_score(y_val, y_val_pred))\n",
    "print(\"Validation R2 (rounded):\", r2_score(y_val, y_val_pred_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Retrain and Evaluate\n",
    "\n",
    "We can now retrain the model on the train+val sets to ensure it sees as many examples as possible while avoiding leakage by leaving the test set untouched. We will use the test set to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on train+val, test on test set\n",
    "X_trainval = pd.concat([X_train, X_val])\n",
    "y_trainval = pd.concat([y_train, y_val])\n",
    "final_model = MultiOutputRegressor(\n",
    "    RandomForestRegressor(\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        **{k.replace('estimator__', ''): v for k, v in grid.best_params_.items()}\n",
    "    )\n",
    ")\n",
    "final_model.fit(X_trainval.values, y_trainval.values)\n",
    "y_test_pred = final_model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Evaluation Results\n",
    "\n",
    "Here we see the results of our testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (raw): 0.4237828080590509\n",
      "Test RMSE (rounded): 0.5160493827160494\n",
      "Test MAE (raw): 0.5340622033383746\n",
      "Test MAE (rounded): 0.4814814814814815\n",
      "Test R2 (raw): 0.7216476057828166\n",
      "Test R2 (rounded): 0.6614602888808354\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation with rounded predictions\n",
    "y_test_pred = final_model.predict(X_test.values)\n",
    "y_test_pred_rounded = np.round(y_test_pred)  # Round predictions to nearest integer\n",
    "\n",
    "print(\"Test RMSE (raw):\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Test RMSE (rounded):\", mean_squared_error(y_test, y_test_pred_rounded))\n",
    "print(\"Test MAE (raw):\", mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"Test MAE (rounded):\", mean_absolute_error(y_test, y_test_pred_rounded))\n",
    "print(\"Test R2 (raw):\", r2_score(y_test, y_test_pred))\n",
    "print(\"Test R2 (rounded):\", r2_score(y_test, y_test_pred_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FTHG_true  FTHG_pred  FTHG_pred_rounded  FTAG_true  FTAG_pred  \\\n",
      "0          1   1.364469                1.0          0   1.045570   \n",
      "1          5   4.334601                4.0          0   0.777992   \n",
      "2          4   2.273197                2.0          2   1.540733   \n",
      "3          0   0.157246                0.0          0   0.775358   \n",
      "4          0   0.523431                1.0          2   1.567010   \n",
      "\n",
      "   FTAG_pred_rounded  \n",
      "0                1.0  \n",
      "1                1.0  \n",
      "2                2.0  \n",
      "3                1.0  \n",
      "4                2.0  \n"
     ]
    }
   ],
   "source": [
    "# Show predictions vs actuals with rounded predictions\n",
    "results = pd.DataFrame({\n",
    "    'FTHG_true': y_test['FTHG'].values,\n",
    "    'FTHG_pred': y_test_pred[:, 0],\n",
    "    'FTHG_pred_rounded': y_test_pred_rounded[:, 0],\n",
    "    'FTAG_true': y_test['FTAG'].values,\n",
    "    'FTAG_pred': y_test_pred[:, 1],\n",
    "    'FTAG_pred_rounded': y_test_pred_rounded[:, 1]\n",
    "})\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Visuals - Feature Importance\n",
    "\n",
    "We can see what features were the most important and had the most weight in the predictions of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most important features:\n",
      "                        feature  importance\n",
      "0                          HTHG    0.714583\n",
      "4                           HST    0.190747\n",
      "80                      odds_hw    0.006149\n",
      "82                      odds_aw    0.005384\n",
      "108   h2h_avg_home_goals_last_5    0.005175\n",
      "3                            AS    0.003859\n",
      "106     defensive_solidity_home    0.003770\n",
      "81                       odds_d    0.003757\n",
      "93   avg_goals_conceded_home_L5    0.003154\n",
      "2                            HS    0.003074\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': final_model.estimators_[0].feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importance.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
