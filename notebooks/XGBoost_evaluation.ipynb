{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we will use the existing pipeline_ex_XGBoost to build and test an XGBoost model to predict the scoreline for EPL games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Import and Data Prep\n",
    "\n",
    "We import the necessary libraries and get the training, validation and testing datasets. These sets have undergone cleaning, preparation and feature engeneering in the original pipeline file, so they are ready to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_XGBoost.py:190: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  db['odds_hw'] = db[home_win_cols].mean(axis=1)\n",
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_XGBoost.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  db['odds_d']  = db[draw_cols].mean(axis=1)\n",
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_XGBoost.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  db['odds_aw'] = db[away_win_cols].mean(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- NaN Check before scaling ---\n",
      "NaNs in X_train: 0\n",
      "NaNs in X_val: 0\n",
      "NaNs in X_test: 0\n",
      "--- NaN Check after scaling ---\n",
      "NaNs in X_train_scaled: 0\n",
      "NaNs in X_val_scaled: 0\n",
      "NaNs in X_test_scaled: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_XGBoost.py:159: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  db[\"h2h_avg_home_goals_last_5\"].fillna(db[\"h2h_avg_home_goals_last_5\"].mean(), inplace=True)\n",
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_XGBoost.py:160: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  db[\"h2h_avg_away_goals_last_5\"].fillna(db[\"h2h_avg_away_goals_last_5\"].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Evaluation Notebook\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "import sys, os\n",
    "\n",
    "# Import pipeline and load data\n",
    "sys.path.append(os.path.abspath('..'))  # Adjust if needed\n",
    "from pipeline_ex_XGBoost import get_train_val_test_data\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_train_val_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train type: <class 'pandas.core.frame.DataFrame'>\n",
      "X_train shape: (3233, 227)\n",
      "y_train type: <class 'pandas.core.frame.DataFrame'>\n",
      "y_train shape: (3233, 2)\n",
      "First 5 y_train columns: ['FTHG', 'FTAG']\n",
      "First 5 X_train columns: ['HTHG', 'HTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'Bb1X2', 'BbMxH', 'BbAvH', 'BbMxD', 'BbAvD', 'BbMxA', 'BbAvA', 'BbOU', 'BbMx_2.5', 'BbAv_2.5', 'BbMx_2.5', 'BbAv_2.5', 'BbAH', 'BbAHh', 'BbMxAHH', 'BbAvAHH', 'BbMxAHA', 'BbAvAHA', 'B365_2.5', 'B365_2.5', 'P_2.5', 'P_2.5', 'Max_2.5', 'Max_2.5', 'Avg_2.5', 'Avg_2.5', 'AHh', 'B365AHH', 'B365AHA', 'PAHH', 'PAHA', 'MaxAHH', 'MaxAHA', 'AvgAHH', 'AvgAHA', 'B365C_2.5', 'B365C_2.5', 'PC_2.5', 'PC_2.5', 'MaxC_2.5', 'MaxC_2.5', 'AvgC_2.5', 'AvgC_2.5', 'AHCh', 'B365CAHH', 'B365CAHA', 'PCAHH', 'PCAHA', 'MaxCAHH', 'MaxCAHA', 'AvgCAHH', 'AvgCAHA', 'BFEH', 'BFED', 'BFEA', 'BFE_2.5', 'BFE_2.5', 'BFEAHH', 'BFEAHA', 'BFECH', 'BFECD', 'BFECA', 'BFEC_2.5', 'BFEC_2.5', 'BFECAHH', 'BFECAHA', 'odds_hw', 'odds_d', 'odds_aw', 'HomeTeam_ID', 'AwayTeam_ID', 'avg_goals_L5_home', 'avg_goals_L5_away', 'avg_shots_home_L5', 'avg_shots_away_L5', 'avg_shots_ont_home_L5', 'avg_shots_ont_away_L5', 'avg_corners_home_L5', 'avg_corners_away_L5', 'avg_goals_conceded_home_L5', 'avg_goals_conceded_away_L5', 'avg_fouls_committed_home_L5', 'avg_fouls_committed_away_L5', 'win_rate_home_L5', 'win_rate_away_L5', 'draw_rate_home_L5', 'draw_rate_away_L5', 'loss_rate_home_L5', 'loss_rate_away_L5', 'home_strength_diff', 'offensive_index_home', 'offensive_index_away', 'defensive_solidity_home', 'defensive_solidity_away', 'h2h_avg_home_goals_last_5', 'h2h_avg_away_goals_last_5', 'HomeTeam_Arsenal', 'HomeTeam_Aston_Villa', 'HomeTeam_Bournemouth', 'HomeTeam_Brentford', 'HomeTeam_Brighton', 'HomeTeam_Burnley', 'HomeTeam_Cardiff', 'HomeTeam_Chelsea', 'HomeTeam_Crystal_Palace', 'HomeTeam_Everton', 'HomeTeam_Fulham', 'HomeTeam_Huddersfield', 'HomeTeam_Ipswich', 'HomeTeam_Leeds', 'HomeTeam_Leicester', 'HomeTeam_Liverpool', 'HomeTeam_Luton', 'HomeTeam_Man_City', 'HomeTeam_Man_United', 'HomeTeam_Manchester_City', 'HomeTeam_Manchester_United', 'HomeTeam_Newcastle', 'HomeTeam_Newcastle_United', 'HomeTeam_Norwich', \"HomeTeam_Nott'm_Forest\", 'HomeTeam_Nottingham_Forest', 'HomeTeam_Sheffield_United', 'HomeTeam_Southampton', 'HomeTeam_Stoke', 'HomeTeam_Swansea', 'HomeTeam_Tottenham', 'HomeTeam_Watford', 'HomeTeam_West_Bromwich_Albion', 'HomeTeam_West_Ham', 'HomeTeam_Wolverhampton_Wanderers', 'HomeTeam_Wolves', 'AwayTeam_Arsenal', 'AwayTeam_Aston_Villa', 'AwayTeam_Bournemouth', 'AwayTeam_Brentford', 'AwayTeam_Brighton', 'AwayTeam_Burnley', 'AwayTeam_Cardiff', 'AwayTeam_Chelsea', 'AwayTeam_Crystal_Palace', 'AwayTeam_Everton', 'AwayTeam_Fulham', 'AwayTeam_Huddersfield', 'AwayTeam_Ipswich', 'AwayTeam_Leeds', 'AwayTeam_Leicester', 'AwayTeam_Liverpool', 'AwayTeam_Luton', 'AwayTeam_Man_City', 'AwayTeam_Man_United', 'AwayTeam_Manchester_City', 'AwayTeam_Manchester_United', 'AwayTeam_Newcastle', 'AwayTeam_Newcastle_United', 'AwayTeam_Norwich', \"AwayTeam_Nott'm_Forest\", 'AwayTeam_Nottingham_Forest', 'AwayTeam_Sheffield_United', 'AwayTeam_Southampton', 'AwayTeam_Stoke', 'AwayTeam_Swansea', 'AwayTeam_Tottenham', 'AwayTeam_Watford', 'AwayTeam_West_Bromwich_Albion', 'AwayTeam_West_Ham', 'AwayTeam_Wolverhampton_Wanderers', 'AwayTeam_Wolves', 'Referee_A_Kitchen', 'Referee_A_Madley', 'Referee_A_Marriner', 'Referee_A_Moss', 'Referee_A_Taylor', 'Referee_C_Kavanagh', 'Referee_C_Pawson', 'Referee_D_Bond', 'Referee_D_Coote', 'Referee_D_England', 'Referee_D_Webb', 'Referee_G_Scott', 'Referee_J_Brooks', 'Referee_J_Gillett', 'Referee_J_Moss', 'Referee_J_Smith', 'Referee_K_Friend', 'Referee_K_Kavanagh', 'Referee_L_Mason', 'Referee_L_Probert', 'Referee_L_Smith', 'Referee_M_Atkinson', 'Referee_M_Dean', 'Referee_M_Donohue', 'Referee_M_Jones', 'Referee_M_Oliver', 'Referee_M_Salisbury', 'Referee_N_Swarbrick', 'Referee_O_Langford', 'Referee_O_Oliver', 'Referee_P_Bankes', 'Referee_P_Tierney', 'Referee_R_East', 'Referee_R_Jones', 'Referee_R_Madley', 'Referee_R_Welch', 'Referee_S_Allison', 'Referee_S_Attwell', 'Referee_S_Barrott', 'Referee_S_Hooper', 'Referee_S_Scott', 'Referee_S_Singh', 'Referee_T_Bramall', 'Referee_T_Harrington', 'Referee_T_Robinson']\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train type:\", type(X_train))\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train type:\", type(y_train))\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"First 5 y_train columns:\", y_train.columns.tolist())\n",
    "print(\"First 5 X_train columns:\", X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Hyperparameter Tuning\n",
    "\n",
    "We tune the hyperparemeters using GridSearchCV to get the optimal model performance. Due to a bug in recent versions of XGBoost, we have to pass both the features and targets as numpy arrays to make the process work,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters: {'estimator__colsample_bytree': 1.0, 'estimator__learning_rate': 0.1, 'estimator__max_depth': 3, 'estimator__n_estimators': 50, 'estimator__subsample': 1.0}\n",
      "Best CV score (neg RMSE): -0.8234924793243408\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [3, 5, 7],\n",
    "    'estimator__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'estimator__subsample': [0.8, 1.0],\n",
    "    'estimator__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create time series cross-validation splits\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "base_model = MultiOutputRegressor(XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1))\n",
    "grid = GridSearchCV(base_model, param_grid, cv=tscv, scoring='neg_root_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "grid.fit(X_train.values, y_train.values)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score (neg RMSE):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Validation Evaluation\n",
    "\n",
    "We validate the model and see how it performs on the validation set. This should give us an idea of how it performs and if the hyperparameter optimization was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE (raw): 0.4681921899318695\n",
      "Validation RMSE (rounded): 0.535891056060791\n",
      "Validation MAE (raw): 0.5570856332778931\n",
      "Validation MAE (rounded): 0.4839108884334564\n",
      "Validation R2 (raw): 0.6895456314086914\n",
      "Validation R2 (rounded): 0.6439706087112427\n"
     ]
    }
   ],
   "source": [
    "# Validation set evaluation with rounded predictions\n",
    "y_val_pred = grid.predict(X_val.values)\n",
    "y_val_pred_rounded = np.round(y_val_pred)  # Round predictions to nearest integer\n",
    "\n",
    "print(\"Validation RMSE (raw):\", mean_squared_error(y_val, y_val_pred))\n",
    "print(\"Validation RMSE (rounded):\", mean_squared_error(y_val, y_val_pred_rounded))\n",
    "print(\"Validation MAE (raw):\", mean_absolute_error(y_val, y_val_pred))\n",
    "print(\"Validation MAE (rounded):\", mean_absolute_error(y_val, y_val_pred_rounded))\n",
    "print(\"Validation R2 (raw):\", r2_score(y_val, y_val_pred))\n",
    "print(\"Validation R2 (rounded):\", r2_score(y_val, y_val_pred_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Retrain and Evaluate\n",
    "\n",
    "We can now retrain the model on the train+val sets to ensure it sees as many examples as possible while avoiding leakage by leaving the test set untouched. We will use the test set to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on train+val, test on test set\n",
    "X_trainval = pd.concat([X_train, X_val])\n",
    "y_trainval = pd.concat([y_train, y_val])\n",
    "final_model = MultiOutputRegressor(\n",
    "    XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        **{k.replace('estimator__', ''): v for k, v in grid.best_params_.items()}\n",
    "    )\n",
    ")\n",
    "final_model.fit(X_trainval.values, y_trainval.values)\n",
    "y_test_pred = final_model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Evaluation Results\n",
    "\n",
    "Here we see the results of our testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (raw): 0.39769604802131653\n",
      "Test RMSE (rounded): 0.4864197373390198\n",
      "Test MAE (raw): 0.5136377215385437\n",
      "Test MAE (rounded): 0.44691359996795654\n",
      "Test R2 (raw): 0.737667441368103\n",
      "Test R2 (rounded): 0.6786786317825317\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation with rounded predictions\n",
    "y_test_pred = final_model.predict(X_test.values)\n",
    "y_test_pred_rounded = np.round(y_test_pred)  # Round predictions to nearest integer\n",
    "\n",
    "print(\"Test RMSE (raw):\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Test RMSE (rounded):\", mean_squared_error(y_test, y_test_pred_rounded))\n",
    "print(\"Test MAE (raw):\", mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"Test MAE (rounded):\", mean_absolute_error(y_test, y_test_pred_rounded))\n",
    "print(\"Test R2 (raw):\", r2_score(y_test, y_test_pred))\n",
    "print(\"Test R2 (rounded):\", r2_score(y_test, y_test_pred_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see comparisons of predictions and actual values to see how our model performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FTHG_true  FTHG_pred  FTHG_pred_rounded  FTAG_true  FTAG_pred  \\\n",
      "0          1   1.425803                1.0          0   1.144145   \n",
      "1          5   4.618654                5.0          0   0.700376   \n",
      "2          4   2.416402                2.0          2   1.422171   \n",
      "3          0   0.175415                0.0          0   0.749795   \n",
      "4          0   0.521366                1.0          2   1.449654   \n",
      "\n",
      "   FTAG_pred_rounded  \n",
      "0                1.0  \n",
      "1                1.0  \n",
      "2                1.0  \n",
      "3                1.0  \n",
      "4                1.0  \n"
     ]
    }
   ],
   "source": [
    "# Show predictions vs actuals with rounded predictions\n",
    "results = pd.DataFrame({\n",
    "    'FTHG_true': y_test['FTHG'].values,\n",
    "    'FTHG_pred': y_test_pred[:, 0],\n",
    "    'FTHG_pred_rounded': y_test_pred_rounded[:, 0],\n",
    "    'FTAG_true': y_test['FTAG'].values,\n",
    "    'FTAG_pred': y_test_pred[:, 1],\n",
    "    'FTAG_pred_rounded': y_test_pred_rounded[:, 1]\n",
    "})\n",
    "print(results.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
